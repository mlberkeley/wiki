Gradient descent is the basic algorithm used to train a [[neural network]].

$$
\theta \leftarrow \theta - \alpha \nabla_\theta \mathcal{L}(\theta)
$$

Applying the gradient descent algorithm in practice requires [[backpropagation]] and [[automatic differentiation]].