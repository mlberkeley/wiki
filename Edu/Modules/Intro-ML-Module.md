# Intro to ML

# Module Dependencies

Strong Dependencies:

None

Weak Dependencies:

None

# Module Overview

- The slides here don’t really go into the math… just trying to introduce course staff, motivate the specific course, etc and give broad strokes intro into what ML is and how we think about it
    - Specifically, thinking of ML as template creation and seeing examples of that
- Also want to bring up data preprocessing and bias variance just because this will be covered multiple times elsewhere if we don’t do it here
    - Basics of data preprocessing: vectorizing data, splitting between train and test, etc
    - Bias variance exemplified with polynomial regression

# Slide Outline

- Intro to course/program/etc and specific motivation
    - Demos
- ML Motivation/what is ML
    - Generally the process of using data to create functions
    - Idea of template creation: we create the outline of a function and let data fill in the free parameters
        - Display this with linear decision boundaries
    - ML is about defining what to learn in a function and how to do it
- Taxonomy of ML
    - Just break down ML into supervised, unsupervised, RL
- ML pipeline
    - Step by step how to solve a problem with ML
    - Includes how we deal with data (datasets, splitting to test/train) and represent it (often with vectors)
    - Loss function motivation/introduction at a high level
        - Can’t improve if we have no metric for how we are doing
- Bias/variance
    - bias: Our bias towards certain values, regardless of how our training dataset changes
    - variance: Our ability to flex with our data and learn new things from it.
    - Use polynomial regression to illustrate this

# Assignment Outline

### Pre Lecture Content

- None

### Post Lecture Content

- Reading: How to read a paper
- MCQ: How to read a paper questions
- MCQ: Some basic linalg/vector calc questions just to get students to go and look into the basic math that we will require
- (Optional): Course specific reading / setups

# Module Links

### Slide Deck Link

- [https://docs.google.com/presentation/d/12tNiQBoI6WKHLChBZqkZnWyH-aAr6TccaSAGgubXyDM/edit#slide=id.g10f080dd5ab_0_65](https://docs.google.com/presentation/d/12tNiQBoI6WKHLChBZqkZnWyH-aAr6TccaSAGgubXyDM/edit#slide=id.g10f080dd5ab_0_65)

### Pre Lecture Links

- **Put links to all documents, articles, videos, etc here

### Post Lecture Links

- **Put links to all documents, articles, videos, etc here

# Author Concern List

- (Post-Decal Comment) Time is ok on this lecture, bias variance is just not well explained overall